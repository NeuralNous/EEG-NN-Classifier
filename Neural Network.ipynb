{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128000, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "import classifier\n",
    "\n",
    "# Для отображения графиков\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "# constats\n",
    "FILENAME = 'data/cleaned_data.csv'\n",
    "# FILENAME = 'data/cleaned_data.csv'\n",
    "SEED = 1\n",
    "FREQ = 128\n",
    "CHUNK_SIZE = 5\n",
    "\n",
    "#loading file\n",
    "data = pd.read_csv(FILENAME)\n",
    "\n",
    "print(data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoding and preparing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "   class           F3          FC5          AF3           F7           T7  \\\n0      0  4195.256410  3400.512819  3465.641024  3137.051280  4166.794872   \n1      0  4195.897436  3405.512819  3474.358973  3141.794869  4168.717949   \n2      0  4194.358974  3410.512819  3434.230768  3133.717946  4169.615384   \n3      0  4182.948718  3406.282049  3445.128203  3132.820510  4168.076923   \n4      0  4184.102564  3405.512819  3482.435896  3133.461536  4163.717949   \n\n            P7           O1           O2           P8           T8  \\\n0  4184.230769  4176.538461  4213.846154  4198.333333  4181.794872   \n1  4188.717949  4173.717949  4206.666667  4187.564102  4176.666667   \n2  4189.743590  4178.461538  4198.333333  4162.051282  4173.076923   \n3  4191.794872  4181.666667  4204.871795  4170.384615  4176.794872   \n4  4195.128205  4184.743590  4216.538461  4190.769231  4180.641026   \n\n            F8          AF4          FC6           F4  \n0  3876.538461  3250.769229  3253.333331  4174.487179  \n1  3891.794871  3302.051280  3268.205126  4182.307692  \n2  3881.025640  3258.076921  3256.282049  4168.461538  \n3  3865.384615  3228.333331  3239.743588  4161.410256  \n4  3876.666666  3281.666665  3251.410254  4171.410256  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>F3</th>\n      <th>FC5</th>\n      <th>AF3</th>\n      <th>F7</th>\n      <th>T7</th>\n      <th>P7</th>\n      <th>O1</th>\n      <th>O2</th>\n      <th>P8</th>\n      <th>T8</th>\n      <th>F8</th>\n      <th>AF4</th>\n      <th>FC6</th>\n      <th>F4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4195.256410</td>\n      <td>3400.512819</td>\n      <td>3465.641024</td>\n      <td>3137.051280</td>\n      <td>4166.794872</td>\n      <td>4184.230769</td>\n      <td>4176.538461</td>\n      <td>4213.846154</td>\n      <td>4198.333333</td>\n      <td>4181.794872</td>\n      <td>3876.538461</td>\n      <td>3250.769229</td>\n      <td>3253.333331</td>\n      <td>4174.487179</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>4195.897436</td>\n      <td>3405.512819</td>\n      <td>3474.358973</td>\n      <td>3141.794869</td>\n      <td>4168.717949</td>\n      <td>4188.717949</td>\n      <td>4173.717949</td>\n      <td>4206.666667</td>\n      <td>4187.564102</td>\n      <td>4176.666667</td>\n      <td>3891.794871</td>\n      <td>3302.051280</td>\n      <td>3268.205126</td>\n      <td>4182.307692</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4194.358974</td>\n      <td>3410.512819</td>\n      <td>3434.230768</td>\n      <td>3133.717946</td>\n      <td>4169.615384</td>\n      <td>4189.743590</td>\n      <td>4178.461538</td>\n      <td>4198.333333</td>\n      <td>4162.051282</td>\n      <td>4173.076923</td>\n      <td>3881.025640</td>\n      <td>3258.076921</td>\n      <td>3256.282049</td>\n      <td>4168.461538</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>4182.948718</td>\n      <td>3406.282049</td>\n      <td>3445.128203</td>\n      <td>3132.820510</td>\n      <td>4168.076923</td>\n      <td>4191.794872</td>\n      <td>4181.666667</td>\n      <td>4204.871795</td>\n      <td>4170.384615</td>\n      <td>4176.794872</td>\n      <td>3865.384615</td>\n      <td>3228.333331</td>\n      <td>3239.743588</td>\n      <td>4161.410256</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4184.102564</td>\n      <td>3405.512819</td>\n      <td>3482.435896</td>\n      <td>3133.461536</td>\n      <td>4163.717949</td>\n      <td>4195.128205</td>\n      <td>4184.743590</td>\n      <td>4216.538461</td>\n      <td>4190.769231</td>\n      <td>4180.641026</td>\n      <td>3876.666666</td>\n      <td>3281.666665</td>\n      <td>3251.410254</td>\n      <td>4171.410256</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if FILENAME == 'data/data.csv':\n",
    "    data.drop(columns='iter', inplace=True)\n",
    "\n",
    "# sort values by class\n",
    "data = data.sort_values('class', kind = 'mergesort')\n",
    "\n",
    "# encode class column\n",
    "data['class'], encode_dict = utils.encode_column(data['class'])\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89600, 15)\n",
      "(38400, 15)\n",
      "(1384, 14, 128) (1384, 14, 65) (1384,)\n",
      "(584, 14, 128) (584, 14, 65) (584,)\n"
     ]
    }
   ],
   "source": [
    "# create train, test from array\n",
    "arr = data.values\n",
    "\n",
    "train, test = utils.eeg_train_test_split(arr, chunk_size= CHUNK_SIZE * FREQ, test_size=0.3, random_state=SEED)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "X_train, X_train_fft, y_train = utils.prepare_train(train, shift=64, save_path='data/')\n",
    "X_test, X_test_fft, y_test = utils.prepare_data(test, save_path='data/')\n",
    "\n",
    "print(X_train.shape, X_train_fft.shape, y_train.shape)\n",
    "print(X_test.shape, X_test_fft.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "datasets = utils.create_dataset((X_train,X_train_fft),y_train),\\\n",
    "           utils.create_dataset((X_test,X_test_fft), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch:   1. Loss: 1.6265. Acc.: 20.21%\n",
      "Epoch 1 best model saved with accuracy: 20.21%\n",
      "Epoch:   2. Loss: 1.5996. Acc.: 20.38%\n",
      "Epoch 2 best model saved with accuracy: 20.38%\n",
      "Epoch 3 best model saved with accuracy: 28.94%\n",
      "Epoch:   4. Loss: 1.5466. Acc.: 26.88%\n",
      "Epoch 7 best model saved with accuracy: 38.36%\n",
      "Epoch:   8. Loss: 1.1448. Acc.: 34.59%\n",
      "Epoch 9 best model saved with accuracy: 39.38%\n",
      "Epoch 10 best model saved with accuracy: 39.73%\n",
      "Epoch 11 best model saved with accuracy: 39.90%\n",
      "Epoch 12 best model saved with accuracy: 40.41%\n",
      "Epoch 15 best model saved with accuracy: 40.75%\n",
      "Epoch:  16. Loss: 0.5146. Acc.: 38.87%\n",
      "Epoch:  32. Loss: 0.2213. Acc.: 20.38%\n",
      "Epoch:  64. Loss: 0.1245. Acc.: 21.58%\n",
      "Epoch: 128. Loss: 0.0529. Acc.: 24.66%\n",
      "Epoch 192 best model saved with accuracy: 41.10%\n",
      "Epoch 199 best model saved with accuracy: 42.29%\n",
      "Epoch 205 best model saved with accuracy: 42.98%\n",
      "Epoch 206 best model saved with accuracy: 43.15%\n",
      "Epoch 224 best model saved with accuracy: 44.01%\n",
      "Epoch 234 best model saved with accuracy: 44.35%\n",
      "Epoch: 256. Loss: 0.0216. Acc.: 36.30%\n",
      "Epoch 358 best model saved with accuracy: 45.55%\n",
      "Epoch: 512. Loss: 0.0186. Acc.: 33.90%\n"
     ]
    }
   ],
   "source": [
    "raw_feat = X_train.shape[1]\n",
    "fft_feat = X_train_fft.shape[1]\n",
    "\n",
    "trn_dl, val_dl = utils.create_loaders(datasets, bs=128)\n",
    "\n",
    "trn_sz = len(y_train)\n",
    "\n",
    "lr = 0.003\n",
    "n_epochs = 3000\n",
    "iterations_per_epoch = len(trn_dl)\n",
    "period = n_epochs * iterations_per_epoch\n",
    "num_classes = 5\n",
    "best_acc = 0\n",
    "patience, trials = 500, 0\n",
    "base = 1\n",
    "step = 2\n",
    "iteration = 0\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "\n",
    "model = classifier.Classifier(raw_feat, fft_feat, num_classes, drop = 0.5).to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "sched = classifier.Scheduler(opt, partial(classifier.one_cycle, t_max=period, pivot=0.1))\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(trn_dl):\n",
    "        iteration += 1\n",
    "        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n",
    "        sched.step(iteration)  # update the learning rate\n",
    "        opt.zero_grad()\n",
    "        out = model(x_raw, x_fft)\n",
    "        loss = criterion(out, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    epoch_loss /= trn_sz\n",
    "    loss_history.append(epoch_loss)\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for batch in val_dl:\n",
    "        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n",
    "        out = model(x_raw, x_fft)\n",
    "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    acc_history.append(acc)\n",
    "\n",
    "    if epoch % base == 0:\n",
    "        print(f'Epoch: {epoch:3d}. Loss: {epoch_loss:.4f}. Acc.: {acc:2.2%}')\n",
    "        base *= step\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'model/' + 'best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break\n",
    "\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def score_model(model, metric, data):\n",
    "    model.eval()  # testing mode\n",
    "    scores = 0\n",
    "    for X_batch, Y_label in data:\n",
    "        Y_pred = model.forward(X_batch.to(device)).float()\n",
    "        scores += metric(Y_pred, Y_label.to(device)).mean().item()\n",
    "\n",
    "    return scores/len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax[0].plot(loss_history, label='loss')\n",
    "ax[0].set_title('Validation Loss History')\n",
    "ax[0].set_xlabel('Epoch no.')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "ax[1].plot(smooth(acc_history, 5)[:-2], label='acc')\n",
    "ax[1].set_title('Validation Accuracy History')\n",
    "ax[1].set_xlabel('Epoch no.')\n",
    "ax[1].set_ylabel('Accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}